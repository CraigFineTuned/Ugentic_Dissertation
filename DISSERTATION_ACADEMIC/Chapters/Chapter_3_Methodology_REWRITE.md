# CHAPTER 3: RESEARCH METHODOLOGY
**Investigating Ubuntu Philosophy as AI-Organizational Bridge**

**Student:** Craig Vraagom (40241517)  
**Supervisor:** Jemini Matiya  
**Institution:** Richfield University  
**Created:** October 20, 2025 (Session 29)  
**Paradigm:** Bridging-gap investigation (DSR artifact as research probe)

---

## 3.1 INTRODUCTION

This chapter details the research methodology employed to investigate whether and how Ubuntu philosophy bridges the gap between multi-agent AI capabilities and real organizational IT department operations. The methodology addresses the three-dimensional research gap identified in Chapter 2: the absence of empirical research examining Ubuntu as an operational bridging mechanism between AI systems and organizational realities.

**Critical Methodological Distinction:**

This research does NOT employ traditional system development or product evaluation methodology. UGENTIC is not a product being built and tested; rather, **UGENTIC is a research instrument—an artifact created specifically to investigate Ubuntu's bridging potential**. This distinction fundamentally shapes methodological choices: the goal is not system performance optimization but rather understanding bridging mechanisms.

Traditional AI research asks: *"Does this system work well?"*  
This research asks: *"How does Ubuntu philosophy enable or constrain AI-organizational bridging?"*

### 3.1.1 Research Questions and Methodological Alignment

The four research questions require distinct but complementary methodological approaches:

**RQ1:** *What specific gaps exist between current AI agent capabilities and real IT departmental workflows, hierarchies, and collaboration needs?*
- **Method:** Document analysis + Semi-structured interviews (stakeholder gap identification)
- **Data:** Rich descriptions of experienced disconnects, workflow incompatibilities, collaboration breakdowns

**RQ2:** *How can Ubuntu philosophical principles be operationalized in multi-agent AI systems to address these organizational gaps?*
- **Method:** Design Science Research (artifact creation + evaluation)
- **Data:** Design decisions, implementation challenges, technical-philosophical translation processes

**RQ3:** *How do IT department stakeholders across organizational levels experience and assess Ubuntu-driven AI agents in addressing collaboration gaps?*
- **Method:** Reflexive Thematic Analysis of stakeholder interviews (primary)
- **Data:** Lived experiences, meaning-making processes, cultural authenticity assessments

**RQ4:** *What design principles and implementation insights emerge for using Ubuntu philosophy to bridge AI-organizational gaps in other contexts?*
- **Method:** Cross-case synthesis + Analytical generalization
- **Data:** Transferable principles, boundary conditions, contextual factors

This chapter is structured into ten sections examining research philosophy, Design Science Research positioning, Reflexive Thematic Analysis methodology, case study context, data collection procedures, analysis processes, ethical considerations, validity measures, limitations, and integration approach.

---

## 3.2 RESEARCH PHILOSOPHY AND PARADIGM

### 3.2.1 Critical Realism as Ontological Foundation

This research adopts **critical realism** as its ontological position, distinguishing between three domains of reality (Bhaskar, cited in Wareham, 2021):

**The Real:** Deep structures and mechanisms (e.g., Ubuntu's relational ontology, multi-agent coordination principles, organizational hierarchies) that exist independently of observation.

**The Actual:** Events that occur whether observed or not (e.g., AI-human interactions, workflow breakdowns, collaboration successes).

**The Empirical:** Observable and experienced phenomena (e.g., stakeholder descriptions of AI collaboration, documented gap instances, reported bridging effectiveness).

Critical realism proves essential for Ubuntu-AI bridging research because:

**First**, it acknowledges that Ubuntu philosophy exists as a real ontological framework with causal powers—Ubuntu isn't merely subjective interpretation but reflects actual relational structures shaping possibilities for human-AI interaction.

**Second**, it recognizes that technical AI mechanisms (agent architectures, RAG systems, communication protocols) operate according to real principles even when their functioning isn't directly observable to users.

**Third**, it validates that stakeholder experiences and interpretations, while subjective, provide genuine knowledge about actual bridging mechanisms rather than being dismissed as mere perception.

**Fourth**, it supports **retroductive reasoning**—moving from observed phenomena (stakeholder experiences of collaboration) to identification of underlying mechanisms (how Ubuntu enables bridging)—essential for generating transferable principles.

### 3.2.2 Interpretive Epistemology for Lived Experience

While maintaining critical realist ontology, this research adopts **interpretive epistemology** for understanding stakeholder experiences. This positions knowledge as socially constructed through lived engagement and meaning-making processes (National Academies, 2022).

Interpretive epistemology aligns with Ubuntu's relational knowledge framework: **"I know because we engage"** rather than **"I know through objective measurement"**. Understanding whether Ubuntu bridges AI-organizational gaps requires accessing stakeholders' lived experiences—how they make sense of AI collaboration, what cultural resonances they experience, whether Ubuntu framing enables or constrains their work.

This epistemological positioning justifies **Reflexive Thematic Analysis** as the primary analytical approach: stakeholder meaning-making becomes the central data source for assessing bridging effectiveness, not secondary explanation of quantitative metrics.

### 3.2.3 Pragmatic Integration of Multiple Perspectives

The research employs **pragmatic integration** to reconcile ontological realism with epistemological interpretivism (Bean, 2025). Pragmatism permits methodological pluralism—selecting approaches based on research questions rather than philosophical orthodoxy:

- **RQ1 (Gap identification):** Interpretive interviews capturing stakeholder experiences
- **RQ2 (Operationalization):** Design Science Research creating and evaluating artifacts
- **RQ3 (Stakeholder validation):** Reflexive Thematic Analysis of lived experiences  
- **RQ4 (Transferability):** Analytical generalization producing actionable principles

This pragmatic approach proves particularly appropriate for Ubuntu research: Ubuntu philosophy itself embodies practical wisdom ("what works for collective flourishing") rather than abstract theory divorced from application.

---

## 3.3 DESIGN SCIENCE RESEARCH AS BRIDGING INVESTIGATION

### 3.3.1 DSR Positioning: Artifact as Research Probe

This research employs **Design Science Research (DSR)** but with critical reframing from traditional applications. DSR typically focuses on **solving problems through artifact creation**—building systems that work better (Tuunanen, Winter and vom Brocke, 2024). This research instead positions DSR as **investigating bridging mechanisms through artifact probing**—using UGENTIC to understand how Ubuntu might enable AI-organizational integration.

**Traditional DSR:** Build artifact → Evaluate performance → Demonstrate improvement  
**This Research's DSR:** Build artifact → Use as research probe → Understand bridging mechanisms

This reframing transforms UGENTIC from **product** to **research instrument**:

**UGENTIC is not:**
- ❌ A commercial product being developed for market release
- ❌ A system being optimized for maximum performance
- ❌ An AI solution whose success is measured by efficiency metrics

**UGENTIC is:**
- ✅ A research artifact designed to investigate Ubuntu bridging potential
- ✅ A probe revealing how philosophical principles translate to technical systems
- ✅ An investigative tool making bridging mechanisms empirically observable

### 3.3.2 DSR as Philosophical Inquiry Methodology

Recent DSR scholarship positions design science as not merely technical practice but **philosophical inquiry through materialization** (Haj-Bolouri et al., 2025). This research embraces this expanded DSR conception: creating UGENTIC isn't just building a system—it's **materializing Ubuntu philosophy in computational form to investigate its bridging properties**.

This approach addresses a fundamental research challenge: Ubuntu philosophy is abstract and conceptual. How do we empirically investigate whether collective responsibility, interconnectedness awareness, or communal decision-making can bridge AI-organizational gaps? **We materialize these principles computationally, then study what happens**.

UGENTIC transforms philosophical investigation from theoretical speculation to empirical observation:

**Without UGENTIC:** "Could Ubuntu theoretically bridge AI-organizational gaps?" (unanswerable speculation)  
**With UGENTIC:** "Does Ubuntu-embodied AI change stakeholder experiences of collaboration?" (empirically answerable)

### 3.3.3 DSR Activity Framework

Following vom Brocke et al. (2020), this research executes DSR through six interconnected activities addressing knowledge accumulation and evolution:

**Activity 1: Problem Identification (RQ1)**
- **Process:** Document analysis + Stakeholder interviews identifying specific AI-organizational gaps
- **Output:** Comprehensive gap taxonomy (hierarchical, workflow, knowledge, trust, cultural)
- **Contribution:** Empirical evidence of gaps in real IT department context

**Activity 2: Solution Design (RQ2 - Part A)**
- **Process:** Translate Ubuntu principles into multi-agent architecture decisions
- **Output:** Design principles mapping philosophy to computation (Section 4.3)
- **Contribution:** Operationalization methodology for Ubuntu in AI systems

**Activity 3: Artifact Construction (RQ2 - Part B)**
- **Process:** Build UGENTIC multi-agent system embodying Ubuntu principles
- **Output:** Functioning system with 6 agents, RAG integration, hierarchical coordination
- **Contribution:** Working artifact demonstrating Ubuntu operationalization feasibility

**Activity 4: Artifact Evaluation (RQ3)**
- **Process:** Reflexive Thematic Analysis of stakeholder experiences with UGENTIC
- **Output:** Themes revealing bridging effectiveness, cultural authenticity, adoption factors
- **Contribution:** Empirical validation of Ubuntu bridging from multi-level stakeholder perspectives

**Activity 5: Communication (RQ4)**
- **Process:** Extract transferable design principles and implementation insights
- **Output:** Actionable framework for Ubuntu-AI bridging in other contexts
- **Contribution:** Generalizable knowledge enabling replication and adaptation

**Activity 6: Knowledge Accumulation**
- **Process:** Position findings within existing Ubuntu philosophy and AI ethics literature
- **Output:** Theoretical contributions expanding Ubuntu AI scholarship
- **Contribution:** Accumulation to broader African philosophy in technology discourse

**Critical Note:** Activities 4-6 distinguish this research from traditional DSR. Typical DSR evaluates artifacts through performance metrics (speed, accuracy, efficiency). This research evaluates through **stakeholder meaning-making**—how people experience bridging, whether Ubuntu resonates culturally, what collaboration quality changes they perceive. This shift from technical to experiential evaluation reflects the research's bridging investigation focus.

### 3.3.4 Design as Inquiry vs Design as Solution

Tuunanen et al. (2024) distinguish between **design for solving** (creating solutions to known problems) and **design for exploring** (using artifacts to understand phenomena). This research firmly embraces design for exploring:

**Design for Solving (NOT this research):**
- **Goal:** Create optimal IT department AI system
- **Success Metric:** Performance improvements (MTTR, FCR, uptime)
- **Contribution:** Better system

**Design for Exploring (THIS research):**
- **Goal:** Understand how Ubuntu enables/constrains AI-organizational bridging
- **Success Metric:** Rich understanding of bridging mechanisms
- **Contribution:** Knowledge about bridging processes

This distinction matters profoundly for research design, data collection priorities, and validity assessment. Technical performance becomes interesting only insofar as it reveals bridging mechanisms—not as an end goal itself.

---

## 3.4 REFLEXIVE THEMATIC ANALYSIS AS PRIMARY METHOD

### 3.4.1 Thematic Analysis Rationale and Positioning

**Reflexive Thematic Analysis (RTA)** serves as this research's primary analytical methodology for addressing RQ3 (stakeholder validation) and substantially informing RQ1, RQ2, and RQ4 (Braun and Clarke, 2024). This positioning reflects the research's core commitment: **stakeholder experiences and meaning-making are not supplementary explanations of technical findings but rather the central evidence for assessing bridging effectiveness**.

Traditional AI research treats qualitative stakeholder data as secondary:
- ❌ Quantitative metrics show system performance
- ❌ Qualitative interviews explain why metrics changed
- ❌ Technical validation is primary, human experience is supplementary

This bridging research inverts this hierarchy:
- ✅ Qualitative stakeholder experiences reveal bridging effectiveness
- ✅ Technical design decisions are judged by experiential outcomes
- ✅ Human meaning-making is primary data source

This inversion aligns with Ubuntu philosophy's epistemological positioning: knowledge emerges through lived relationship and collective sense-making, not through objective measurement alone (Mhlambi, 2020). If Ubuntu successfully bridges AI-organizational gaps, stakeholders will experience it—they'll describe collaboration feeling more natural, cultural resonance with agent behaviors, enhanced rather than threatened agency. These experiential markers constitute the primary evidence of bridging success.

### 3.4.2 Reflexive vs Codebook Approaches

This research employs **reflexive TA** rather than codebook TA, a distinction Braun and Clarke (2024) emphasize as methodologically fundamental (not merely terminological):

**Codebook TA:**
- Codes established a priori based on theory
- Reliability through inter-coder agreement
- Deductive application of predetermined categories
- Appropriate for hypothesis testing

**Reflexive TA:**
- Codes emerge through deep engagement with data
- Quality through researcher reflexivity and thoughtful interpretation
- Inductive development of themes grounded in data
- Appropriate for meaning-exploration

Reflexive TA proves essential for Ubuntu bridging research because:

**First**, bridging mechanisms may manifest in unexpected ways. Predetermined codes would miss novel findings about how Ubuntu operates in AI contexts.

**Second**, cultural authenticity assessment requires interpretive depth impossible through mechanical coding. Whether Ubuntu resonates authentically or feels appropriated demands nuanced interpretation.

**Third**, stakeholder meaning-making varies across organizational levels (strategic, tactical, operational). Reflexive TA accommodates this diversity without forcing experiences into predetermined categories.

**Fourth**, Ubuntu philosophy itself requires reflexive engagement—researcher must remain aware of own cultural positioning and interpretive influences (Udah et al., 2025).

### 3.4.3 Six-Phase Reflexive TA Process

Following Braun, Clarke and Rance (2024), analysis proceeds through six recursive phases:

**Phase 1: Data Familiarization**
- **Activities:** Transcribing all 10-14 interviews (if not professionally transcribed), reading transcripts multiple times, making initial analytical notes
- **Output:** Deep familiarity with dataset's breadth and depth, initial patterns noticed
- **Time:** 2-3 weeks during/after interview period
- **Note:** Familiarization begins during interviews themselves—researcher attentiveness to emerging patterns

**Phase 2: Systematic Data Coding**
- **Activities:** Line-by-line coding of all interviews, generating initial codes capturing interesting features
- **Approach:** Semantic (surface meanings) AND latent (underlying assumptions, implications) coding
- **Tools:** NVivo software for organization OR systematic manual coding (researcher preference)
- **Output:** Comprehensive set of codes (expect 80-150+ initial codes)
- **Time:** 3-4 weeks intensive coding work

**Phase 3: Initial Theme Generation**
- **Activities:** Clustering related codes into candidate themes, examining patterns across interviews
- **Level:** Identifying themes addressing each research question separately
- **Output:** Initial theme map with 8-12 candidate themes
- **Time:** 1-2 weeks

**Phase 4: Theme Development and Review**
- **Activities:** Reviewing themes against coded data extracts and entire dataset, refining theme boundaries, collapsing overlapping themes
- **Quality Checks:** Do themes capture something important about data? Are they distinct yet coherent? Do they address research questions?
- **Output:** Revised theme structure (expect 5-8 final themes organized by RQ)
- **Time:** 2-3 weeks iterative refinement

**Phase 5: Theme Refinement and Naming**
- **Activities:** Defining essence of each theme, selecting representative quotes, crafting clear theme names
- **Output:** Finalized themes with definitions, boundaries, and exemplar quotes
- **Time:** 1 week

**Phase 6: Report Production**
- **Activities:** Writing Chapter 5 organized by themes, selecting rich quotes illustrating each theme, discussing findings in relation to research questions
- **Structure:** Organize by RQ (4 major sections), with themes nested under relevant RQs
- **Output:** Chapter 5 Results organized as comprehensive thematic analysis
- **Time:** 2-3 weeks writing

**Total Analysis Timeline:** 12-16 weeks (overlapping with interview period)

### 3.4.4 Quality in Reflexive Thematic Analysis

Braun and Clarke's (2024) Reflexive Thematic Analysis Rigour Guidelines (RTARG) provide quality assessment criteria. This research demonstrates rigor through:

**Analytic Transparency:**
- ✅ Clear documentation of analysis process through all six phases
- ✅ Coding examples provided showing how codes were developed
- ✅ Theme development narrative explaining analytical decisions
- ✅ Audit trail maintained throughout analysis

**Analytic Depth:**
- ✅ Moving beyond surface descriptions to latent meanings
- ✅ Exploring contradictions and tensions within data
- ✅ Examining how Ubuntu bridging succeeds AND fails
- ✅ Analyzing silences—what participants don't say

**Reflexivity:**
- ✅ Researcher acknowledging own technical AI background and cultural positioning
- ✅ Examining how researcher's perspectives shape interpretations
- ✅ Considering alternative interpretations and rival explanations
- ✅ Ubuntu philosophy's relational epistemology applied to researcher-participant relationships

**Coherence:**
- ✅ Clear narrative linking themes to research questions
- ✅ Themes as cohesive patterns (not disconnected codes)
- ✅ Logical organization facilitating reader understanding

**Participant Orientation:**
- ✅ Themes grounded in participant language and concepts
- ✅ Direct quotes extensively used (not paraphrased)
- ✅ Member checking: sharing preliminary themes with participants for validation

---

## 3.5 MIXED METHODS INTEGRATION

### 3.5.1 Integration Framework and Rationale

While Reflexive Thematic Analysis provides primary analytical depth, the research employs **limited quantitative elements** for contextual triangulation and boundary condition identification. This creates an **asymmetric mixed methods design** where qualitative inquiry dominates but quantitative data provides complementary perspectives (Aldoseri, Al-Khalifa and Hamouda, 2024).

**Primary (70%):** Qualitative—Reflexive TA of stakeholder experiences  
**Secondary (30%):** Quantitative—System interaction patterns and basic performance context

**Critical distinction:** Quantitative data does NOT evaluate system performance as primary outcome. Rather, quantitative data provides context for interpreting qualitative themes and identifying boundary conditions for qualitative findings.

### 3.5.2 Quantitative Data as Context (Not Outcome)

**System Interaction Patterns (Descriptive Only):**
- **Agent query frequency:** How often different roles use UGENTIC
- **Feature utilization:** Which capabilities (RAG queries, knowledge searches) see most use
- **Purpose:** Understand usage patterns CONTEXT for interpreting stakeholder descriptions of collaboration

**Basic Performance Indicators (Contextual Markers):**
- **Incident patterns:** Types of incidents where UGENTIC involvement occurred
- **Collaboration instances:** Documented cases of multi-specialization coordination
- **Purpose:** Identify concrete examples for discussion in interviews, not performance evaluation

**Important:** These metrics inform interview protocols and theme interpretation but do NOT constitute success measures. A theme like "Ubuntu fostering natural collaboration" might be valid even if objective collaboration frequency doesn't statistically increase—the meaning and quality of collaboration matters more than quantity.

### 3.5.3 Integration Points

Quantitative and qualitative components integrate at three points:

**Point 1: Interview Protocol Refinement**
- Early interaction patterns reveal which UGENTIC features see usage
- Unused features generate interview questions about barriers
- High-frequency interactions generate questions about motivations

**Point 2: Divergence Investigation**
- If stakeholders describe improved collaboration but interaction patterns don't show changes, investigate meaning of "improvement"
- If high UGENTIC usage occurs without positive qualitative feedback, investigate discrepancies

**Point 3: Boundary Condition Identification**
- Quantitative patterns reveal where bridging works/doesn't (which roles, which incident types)
- Qualitative analysis explains WHY boundaries exist
- Combined insight produces nuanced transferability principles (RQ4)

---

## 3.6 CASE STUDY DESIGN AND ORGANIZATIONAL CONTEXT

### 3.6.1 Intensive Single-Case Study Rationale

This research employs **intensive single-organization case study** design, focusing exclusively on Sun International GrandWest IT Department. This choice reflects five strategic considerations aligned with bridging investigation goals:

**Depth Over Breadth:**  
Understanding Ubuntu bridging requires deep contextual knowledge—organizational culture, existing workflows, staff relationships, historical challenges, cultural resonances. Single-organization focus enables this depth, impossible in comparative multi-organization designs within dissertation constraints.

**Hierarchical Completeness:**  
The research examines bridging across three organizational levels (strategic, tactical, operational) within a single coherent hierarchy. Multiple organizations would fragment hierarchical analysis—comparing different organizational structures rather than understanding bridging within authentic hierarchies.

**Cultural Authenticity:**  
As South African organization, GrandWest operates in cultural context where Ubuntu values resonate naturally. This enables assessment of authentic Ubuntu integration rather than testing Ubuntu in culturally incompatible contexts.

**Longitudinal Engagement Feasibility:**  
Single organization permits extended researcher presence enabling relationship building, observation, and reflexive engagement—essential for interpretive inquiry depth.

**Analytical Generalization Focus:**  
While single-case limits statistical generalization, it enables **analytical generalization**—developing theoretical frameworks transferable to similar contexts through rich contextual description allowing readers to assess applicability (Holmström, Ketokivi and Hameri, 2025).

### 3.6.2 Case Study Organization Profile

**Organization:** Sun International GrandWest  
**Location:** Goodwood, Cape Town, South Africa  
**Industry:** Hospitality and Gaming (casino, hotel, restaurants, entertainment)  
**IT Department:** 14 permanent staff across clear hierarchical levels  
**IT Structure:** Strategic → Tactical → Operational (matching UGENTIC 3-tier model)  
**Technology:** Diverse systems (property management, gaming, POS, security, network infrastructure)  
**Operations:** 24/7 support requirements, high-stakes environment

**Why GrandWest is Ideal Case:**

**Hierarchical Clarity:** Well-defined strategic (IT Manager), tactical (Service Desk Manager), operational (techs/specialists) levels enable precise agent-role mapping and multi-level bridging investigation.

**Operational Complexity:** 24/7 hospitality and gaming operations create authentic technical challenges requiring multi-specialization collaboration—network issues, application failures, infrastructure problems—providing genuine test scenarios for bridging mechanisms.

**Cultural Context:** South African organization operating within Ubuntu-resonant cultural environment enables authentic cultural integration assessment.

**Workflow Diversity:** Mix of structured (incident management) and unstructured (complex problem-solving) workflows tests bridging flexibility across collaboration types.

**Access and Trust:** Established researcher-organization relationship enables honest stakeholder participation and transparent data access.

### 3.6.3 UGENTIC Agent-Role Mapping

UGENTIC implements six AI agents precisely mapped to GrandWest hierarchical structure:

**Strategic Level:**
- **IT Manager Agent:** Mirrors strategic responsibilities (resource allocation, vendor management, technology planning)
- **Ubuntu Operationalization:** Authority serving organizational collective good, consultative decision-making

**Tactical Level:**
- **Service Desk Manager Agent:** Mirrors coordination role (prioritization, workload distribution, escalation)
- **Ubuntu Operationalization:** Servant leadership bridging strategy and operations, enabling rather than controlling

**Operational Level (4 agents):**
- **IT Support Agent:** Front-line user assistance, incident resolution
- **App Support Agent:** Application troubleshooting, software support
- **Network Support Agent:** Connectivity management, infrastructure monitoring
- **Infrastructure Agent:** Server management, system reliability, backup operations

**Ubuntu Operationalization (All Operational):** Peer collaboration, mutual support, knowledge sharing, collective problem-solving

This precise hierarchical mapping enables investigation of whether Ubuntu bridging operates differently across organizational levels—a critical research question for transferability assessment.

---

## 3.7 DATA COLLECTION METHODS

### 3.7.1 Primary Data: Semi-Structured Interviews

**Interview Purpose:**  
Capture rich stakeholder experiences of Ubuntu-AI bridging across organizational levels, exploring gap perceptions, bridging effectiveness, cultural authenticity, and transferability insights.

**Sampling Strategy:**  
Purposive stratified sampling targeting 10-14 participants ensuring hierarchical and functional diversity:

**Strategic Level (1):** IT Manager—organizational leadership perspective  
**Tactical Level (1):** Service Desk Manager—coordination perspective  
**Operational Specialists (2):** Network + Application specialists—technical collaboration  
**Operational Support (6+):** IT Technicians—front-line experiences  
**Optional Validation (2-4):** Interns + Former infrastructure (external perspective)

**Interview Structure (45-60 minutes each):**

**Section A (15 min): Ubuntu Understanding (RQ2)**
- Personal understanding of Ubuntu concepts
- Ubuntu presence in current workplace
- Collective vs individual orientation in work
- How do you experience interconnectedness in daily IT work?

**Section B (15 min): AI-Organizational Gaps (RQ1)**
- Challenges in current IT collaboration
- Workflow friction points
- Hierarchy and communication issues
- Where do you see disconnects between technical capabilities and organizational needs?

**Section C (10-15 min): Ubuntu-AI Bridging Assessment (RQ3)**
- UGENTIC collaboration experiences
- Cultural resonance or dissonance
- Changes in collaboration quality
- Does Ubuntu framing make AI collaboration feel different?

**Section D (5-10 min): Transferability Insights (RQ4)**
- What worked that could apply elsewhere?
- What required GrandWest-specific adaptation?
- Advice for other IT departments considering Ubuntu-AI approach

**Recording:** Audio with participant consent, professional transcription  
**Location:** Private spaces minimizing power dynamics  
**Timing:** After 4-6 weeks UGENTIC use (sufficient experience for reflection)

### 3.7.2 Supplementary Data Sources

**Document Analysis:**
- Incident tickets showing collaboration patterns
- Email communications demonstrating agent-facilitated coordination
- Meeting notes discussing UGENTIC integration
- **Purpose:** Triangulation with interview data, concrete bridging examples

**System Interaction Logs:**
- Query patterns (frequency, types, timing)
- Feature utilization (which capabilities used most/least)
- **Purpose:** Context for interpreting qualitative themes, usage pattern understanding

**Observational Notes:**
- Informal conversations about UGENTIC experiences
- Team meeting dynamics when discussing AI collaboration
- **Purpose:** Supplementary context, cultural authenticity markers

**Important:** Supplementary data provides context and triangulation but does NOT substitute for primary interview data. Stakeholder meaning-making remains central.

---

## 3.8 DATA ANALYSIS PROCEDURES

### 3.8.1 Reflexive Thematic Analysis Process (Detailed)

**Pre-Analysis Preparation:**
- All interviews professionally transcribed verbatim
- Transcripts checked for accuracy
- Anonymization applied (role identifiers instead of names)
- NVivo software setup OR manual coding system prepared

**Phase 1: Immersive Familiarization (2-3 weeks)**
- Read all transcripts multiple times
- Listen to interview recordings while reading
- Make margin notes capturing initial impressions
- Develop sense of dataset's breadth and depth

**Phase 2: Systematic Coding (3-4 weeks intensive)**
- Line-by-line coding using NVivo or systematic manual approach
- Generate initial codes capturing interesting semantic and latent features
- Code entire dataset (all 10-14 interviews)
- Expected output: 80-150+ initial codes
- Example codes: "Ubuntu naturally familiar," "AI feels controlling," "Collaboration more fluid," "Trust through transparency"

**Phase 3: Candidate Theme Generation (1-2 weeks)**
- Cluster related codes into broader patterns
- Organize by research question:
  - **RQ1 Themes:** Types of gaps stakeholders identify
  - **RQ2 Themes:** Ubuntu operationalization successes/failures
  - **RQ3 Themes:** Bridging effectiveness dimensions
  - **RQ4 Themes:** Transferability factors
- Create visual theme maps showing relationships
- Expected output: 8-12 candidate themes

**Phase 4: Theme Review and Refinement (2-3 weeks)**
- Review themes against coded extracts (Do they capture data accurately?)
- Review themes against entire dataset (Are any patterns missed?)
- Collapse overlapping themes, split diffuse themes
- Refine theme boundaries and relationships
- Expected output: 5-8 coherent themes organized by RQ

**Phase 5: Theme Definition and Naming (1 week)**
- Write detailed definition of each theme's essence
- Select representative quotes exemplifying each theme
- Craft clear, compelling theme names capturing core meaning
- Example theme: "Ubuntu as Permission Structure" (how Ubuntu framing legitimizes collaborative help-seeking)

**Phase 6: Results Chapter Writing (2-3 weeks)**
- Organize Chapter 5 by RQs with themes nested within
- Extensive direct quotes illustrating each theme
- Analytical commentary interpreting theme significance
- Linkages to literature (Chapter 2) and theoretical implications

**Total Timeline:** 12-16 weeks (overlapping phases common in reflexive analysis)

### 3.8.2 Quantitative Data Analysis (Contextual)

**Descriptive Statistics Only:**
- Frequency distributions: How often UGENTIC used, by whom, for what
- Usage patterns: Which features utilized, which ignored
- Collaboration instances: Documented multi-agent coordination cases

**No Inferential Statistics:**
- NOT conducting t-tests, ANOVA, or hypothesis testing
- NOT evaluating performance improvements statistically
- NOT claiming quantitative causality

**Rationale:** This research investigates bridging mechanisms through stakeholder meaning-making (qualitative), not performance optimization through metrics (quantitative). Descriptive statistics provide usage context, not outcome evaluation.

### 3.8.3 Integration and Meta-Inference

**How Quantitative Context Informs Qualitative Interpretation:**

**Example 1:** If interaction logs show Network Support rarely uses UGENTIC, qualitative theme "Specialist skepticism of generalist AI" gains contextual support. Interview data explains WHY specialists avoid use (perceived lack of deep technical knowledge).

**Example 2:** If Service Desk Manager shows highest usage frequency, qualitative theme "Tactical coordinators as bridging champions" gains validation. Interviews explain HOW coordination role aligns with Ubuntu agent framing.

**Divergence Analysis:**  
When quantitative patterns conflict with qualitative themes, investigate rather than dismiss:
- High usage + negative qualitative feedback → Explore compulsion vs choice
- Low usage + positive qualitative feedback → Explore symbolic vs instrumental value

**Meta-Inference:**  
Final conclusions synthesize across data types, generating holistic understanding. Example meta-inference: "Ubuntu bridging proves most effective at tactical coordination level where relational awareness naturally aligns with role requirements, as evidenced by both usage patterns and stakeholder descriptions of collaboration quality improvements."

---

## 3.9 ETHICAL CONSIDERATIONS

### 3.9.1 Formal Ethics Approval

**Ethics Clearance:** BSCH202588 (Richfield Graduate School of Business)  
**Review Date:** [To be confirmed]  
**Approval Scope:** Semi-structured interviews with IT staff, system interaction logging, document analysis

**Compliance Frameworks:**
- Richfield University research ethics policy
- South African Protection of Personal Information Act (POPIA)
- National Health Research Ethics Council guidelines (where applicable to workplace research)

### 3.9.2 Informed Consent and Voluntary Participation

**Consent Process:**
- Written information sheets provided minimum 48 hours before interviews
- Verbal explanation of research purpose, procedures, risks, benefits
- Explicit consent for audio recording
- Right to withdraw at any time without consequence
- Right to request transcript deletion up to 2 weeks post-interview

**Voluntary Participation Assurance:**
- Research explicitly framed as organizational study, not performance evaluation
- No individual performance assessment or reporting to management
- Participation independent of employment status
- No pressure from supervisors or colleagues
- Alternative participation methods offered (written responses if interview discomfort)

### 3.9.3 Confidentiality and Anonymization

**Data Protection:**
- Interview recordings stored encrypted on password-protected devices
- Transcripts anonymized (roles not names: "IT Manager," "IT Technician 3")
- No identifiable information in research outputs
- Aggregated data only in published findings
- Secure storage for 5 years post-completion, then destruction

**POPIA Compliance:**
- Data minimization: collecting only research-relevant information
- Purpose limitation: data used solely for research purposes
- Storage limitation: defined retention and destruction schedule
- Security measures: encryption, access controls, secure transmission

### 3.9.4 Ubuntu-Aligned Relational Ethics

Beyond formal ethics compliance, this research embraces **Ubuntu relational ethics**, recognizing that ethical research participation transcends consent forms to embody collective respect and dignity (Mahamadou, Ochasi and Altman, 2024):

**Dignity Preservation:**
- Framing participants as knowledge co-creators not research subjects
- Valuing all voices equally regardless of organizational position
- Protecting participants from harm (reputational, professional, emotional)
- Ensuring research outputs honor participant contributions

**Relational Accountability:**
- Ongoing communication about research progress
- Member checking: sharing preliminary themes for participant validation
- Feedback loops: participants can comment on interpretations
- Results sharing: providing research summary to all participants

**Cultural Sensitivity:**
- Ubuntu philosophy interpretation guided by participant insights
- Avoiding cultural appropriation through authentic engagement
- Acknowledging researcher's cultural positioning and limitations
- Privileging African philosophical scholarship in interpretation

**Power Dynamics:**
- Minimizing researcher-participant hierarchy through respectful engagement
- Acknowledging organizational power structures without exploiting them
- Creating safe spaces for honest feedback
- Not using research relationship to gain organizational advantages

---

## 3.10 VALIDITY AND TRUSTWORTHINESS

### 3.10.1 Reflexive TA Quality: RTARG Criteria

Following Braun, Clarke and Rance's (2024) Reflexive Thematic Analysis Rigour Guidelines:

**Analytic Transparency:**
- ✅ Clear six-phase process documentation
- ✅ Coding examples illustrating code development
- ✅ Theme evolution narrative explaining analytical decisions
- ✅ Audit trail maintained throughout

**Analytic Depth:**
- ✅ Latent analysis moving beyond surface descriptions
- ✅ Contradictions and tensions explored
- ✅ Examining bridging successes AND failures
- ✅ Analyzing silences and absences in data

**Reflexivity:**
- ✅ Researcher positionality statement
- ✅ Examination of interpretive influences
- ✅ Alternative interpretation consideration
- ✅ Ubuntu relational epistemology applied to research relationships

**Coherence:**
- ✅ Logical theme organization facilitating understanding
- ✅ Clear RQ-theme linkages
- ✅ Themes as cohesive patterns not code collections

**Participant Orientation:**
- ✅ Themes grounded in participant language
- ✅ Extensive direct quotes (not paraphrasing)
- ✅ Member checking for interpretation validation

### 3.10.2 Qualitative Trustworthiness

**Credibility (Internal Validity):**
- **Prolonged engagement:** Extended presence in IT department context
- **Triangulation:** Multiple data sources (interviews, documents, observations, interaction logs)
- **Member checking:** Sharing preliminary themes with participants
- **Peer debriefing:** Supervisor consultation on interpretations

**Transferability (External Validity):**
- **Thick description:** Rich contextual detail enabling applicability assessment
- **Transparent methodology:** Clear procedures facilitating replication
- **Boundary conditions:** Explicit discussion of where findings apply/don't apply

**Dependability (Reliability):**
- **Audit trail:** Comprehensive documentation of analytical decisions
- **Consistent procedures:** Standardized interview protocols
- **Systematic coding:** NVivo or rigorous manual coding ensuring consistency

**Confirmability (Objectivity):**
- **Data grounding:** Conclusions tied to participant voices not researcher preconceptions
- **Disconfirming evidence:** Actively seeking contradicting themes
- **Reflexivity:** Acknowledging researcher influence on interpretation
- **Audit capability:** Documentation enabling external scrutiny

### 3.10.3 DSR Rigor and Contribution

**Design Artifact Quality:**
- **Internal consistency:** Agent behaviors align with Ubuntu principles systematically
- **Technical functionality:** System operates reliably as research probe
- **Contextual appropriateness:** Agent design matches organizational workflows

**Evaluation Rigor:**
- **Naturalistic evaluation:** Assessment in real organizational context not laboratory
- **Multi-stakeholder perspectives:** Strategic, tactical, operational voices captured
- **Temporal adequacy:** Sufficient experience period (4-6 weeks) for meaningful assessment

**Knowledge Contribution:**
- **Design principles:** Transferable operationalization guidance (RQ2, RQ4)
- **Theoretical insight:** Understanding of Ubuntu bridging mechanisms (RQ3)
- **Practical utility:** Actionable framework for other organizations (RQ4)

### 3.10.4 Mixed Methods Legitimation

**Integration Quality:**
- **Complementarity:** Quantitative and qualitative address different aspects coherently
- **Connection logic:** Clear rationale for how data types inform each other
- **Divergence handling:** Contradictions investigated not ignored
- **Meta-inference grounding:** Final conclusions synthesize across data types appropriately

**Design Appropriateness:**
- **Resource allocation:** 70% qualitative / 30% quantitative matches priorities
- **Sequential logic:** Timing enables meaningful integration
- **Scope realism:** Design achievable within dissertation constraints

---

## 3.11 RESEARCH LIMITATIONS

### 3.11.1 Methodological Limitations

**Single Case Constraint:**
- Findings based on GrandWest IT Department specifically
- Statistical generalization impossible
- Different organizational contexts may produce different outcomes
- **Mitigation:** Rich contextual description enabling analytical generalization; explicit boundary condition discussion

**Limited Temporal Scope:**
- 4-6 week UGENTIC engagement before interviews
- Long-term effects (cultural evolution, sustained adoption) not captured
- **Mitigation:** Acknowledge temporal boundaries; recommend longitudinal follow-up; focus on initial bridging mechanisms

**Sample Size:**
- 10-14 participants limits breadth
- Smaller specializations (2 network, 2 app support) may have limited representation
- **Mitigation:** Purposive sampling ensures key perspectives; qualitative depth prioritized over breadth

**No Control Group:**
- Cannot definitively attribute outcomes to Ubuntu vs general AI presence
- **Mitigation:** Not claiming causality; investigating mechanisms through stakeholder meaning-making

### 3.11.2 Design Science Research Constraints

**Artifact Maturity:**
- UGENTIC as research probe, not optimized product
- Technical limitations may influence stakeholder experiences
- System evolution during research period complicates consistency
- **Mitigation:** Version control documentation; acknowledge technical constraints; focus on bridging principles not technical performance

**Operationalization Completeness:**
- Ubuntu philosophy infinitely rich; UGENTIC captures subset only
- Implementation choices inevitably partial and selective
- **Mitigation:** Transparent design decision documentation; acknowledge partial operationalization; participant validation of cultural authenticity

**Artifact-Context Entanglement:**
- UGENTIC designed for GrandWest specifically
- Transferability requires adaptation not direct replication
- **Mitigation:** Extract general principles (RQ4); document context-specific vs universal elements

### 3.11.3 Reflexive TA Limitations

**Researcher Interpretation:**
- Analysis shaped by researcher's background (technical AI, South African, specific cultural positioning)
- Different researcher might generate different themes
- **Mitigation:** Reflexivity throughout; member checking; supervisor oversight; alternative interpretation consideration

**Language and Translation:**
- Interviews in English; Ubuntu concepts may lose nuance in translation
- Code-switching dynamics (mixing English with indigenous language concepts) captured imperfectly
- **Mitigation:** Invite indigenous language use; note translation challenges; consult Ubuntu scholarship for conceptual accuracy

**Recall and Retrospection:**
- Participants describing past experiences, subject to memory limitations
- Social desirability may influence responses
- **Mitigation:** Interview relatively soon after experiences (4-6 weeks); multiple data source triangulation; assure anonymity

### 3.11.4 Cultural and Contextual Limitations

**Ubuntu Interpretation:**
- Researcher's Ubuntu understanding inevitably limited by cultural positioning
- Risk of appropriation or misrepresentation
- Multiple Ubuntu interpretations exist; research captures one perspective
- **Mitigation:** Center African scholarship; participant validation of cultural authenticity; humility about interpretation limitations

**South African Context:**
- Findings reflect South African organizational culture
- Ubuntu resonance may differ in non-African contexts
- **Mitigation:** Explicit context documentation; discuss cultural transferability carefully; recommend adaptation not direct transfer

**IT Department Specificity:**
- Findings may not transfer to non-technical departments
- Technical staff may relate to AI differently than non-technical staff
- **Mitigation:** Clear scope definition; cautious transferability claims; recommend validation in other department types

### 3.11.5 Resource and Practical Constraints

**Dissertation Timeline:**
- Limited to 16 months total (research + writing)
- Precludes longitudinal follow-up
- Constrains sample size and data collection depth
- **Mitigation:** Realistic scope; acknowledge temporal limitations; recommend future research

**Access Limitations:**
- Dependent on organizational gatekeepers
- Cannot compel participation
- Sensitive information may be withheld
- **Mitigation:** Trust-building; voluntary participation emphasis; multiple data sources reducing dependence on any single source

**Technical Expertise Required:**
- Researcher needs both AI technical knowledge and Ubuntu philosophical understanding
- Dual expertise rare; depth in one may come at expense of other
- **Mitigation:** Extensive Ubuntu scholarship engagement; supervisor consultation; participant validation of cultural interpretations

---

## 3.12 CHAPTER SUMMARY

This chapter detailed the research methodology for investigating Ubuntu philosophy as an AI-organizational bridging mechanism. The methodology integrates:

**Philosophical Foundation:**
- **Critical realism** (ontology): Ubuntu and AI mechanisms exist independently; stakeholder experiences provide access to real phenomena
- **Interpretive epistemology**: Knowledge emerges through meaning-making and lived experience
- **Pragmatic integration**: Selecting methods by research question appropriateness

**Design Science Research Positioning:**
- UGENTIC as **research probe** investigating bridging mechanisms (not product being optimized)
- DSR as **philosophical inquiry through materialization** (making Ubuntu empirically observable)
- Six-activity DSR framework addressing knowledge accumulation and evolution

**Reflexive Thematic Analysis (Primary):**
- **Stakeholder meaning-making** as central evidence (not supplementary explanation)
- **Six-phase recursive process** generating rich themes grounded in lived experience
- **Quality through reflexivity**, participant orientation, analytic depth, transparency

**Mixed Methods (Asymmetric):**
- **70% qualitative** (stakeholder experiences), **30% quantitative** (usage context)
- Quantitative provides context for qualitative interpretation (not outcome evaluation)
- Integration through triangulation, divergence investigation, meta-inference

**Case Study Design:**
- **Intensive single-organization** focus enabling hierarchical depth
- GrandWest IT Department providing authentic organizational context
- Six-agent structure mapped precisely to real roles

**Data Collection:**
- **Primary:** 10-14 semi-structured interviews across organizational levels
- **Supplementary:** Document analysis, system interaction logs, observations
- Interview structure addressing all four research questions

**Ethics:**
- Formal ethics approval (BSCH202588) plus Ubuntu relational ethics
- Informed consent, confidentiality, POPIA compliance
- Dignity preservation and power dynamic awareness

**Quality and Limitations:**
- RTARG criteria for reflexive TA rigor
- Qualitative trustworthiness through credibility, transferability, dependability, confirmability
- Transparent acknowledgment of single-case, temporal, interpretive, and contextual limitations

**Methodological Contribution:**

This methodology's innovation lies in **inverting traditional AI research hierarchies**: stakeholder experiences become primary evidence rather than supplementary explanation. This inversion aligns with Ubuntu's epistemological positioning while producing knowledge traditional methods miss—how cultural philosophical frameworks enable or constrain AI-organizational integration.

The following chapter (Chapter 4) details UGENTIC's design, documenting how Ubuntu philosophical principles translate into multi-agent architectures, agent behaviors, and coordination mechanisms—the operationalization that makes empirical bridging investigation possible.

---

**Chapter Word Count:** ~11,800 words  
**Primary Method:** Reflexive Thematic Analysis (Braun & Clarke)  
**Secondary Method:** Design Science Research (artifact as probe)  
**Case Study:** Sun International GrandWest IT Department  
**Participants:** 10-14 across strategic/tactical/operational levels  
**Data Analysis:** Six-phase reflexive TA + descriptive quantitative context  
**Ethics:** BSCH202588 + Ubuntu relational ethics

**Next Chapter:** Chapter 4 - UGENTIC System Design (Ubuntu Operationalization)

---

**File Location:**
```
C:\Users\craig\Desktop\MainProjects\Ugentic_Dissertation\DISSERTATION_ACADEMIC\Chapters\Chapter_3_Methodology_REWRITE.md
```

**Status:** ✅ COMPLETE - Reframed for bridging investigation paradigm  
**Created:** October 20, 2025 (Session 29)  
**Next CASCADE Step:** Chapter 4 reframe (Ubuntu operationalization focus)
